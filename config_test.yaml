max_samples: 4

num_of_itr: 2

train_paths:
  - '/Users/juliankleutgens/Downloads/reverse_engineering/generated_tasks'
  - '/Users/juliankleutgens/training_data'


test_paths:
  - '/Users/juliankleutgens/PycharmProjects/task2seq_T5/data_test/ct_schema'
  - '/Users/juliankleutgens/PycharmProjects/task2seq_T5/data_test/gl_schema'
  - '/Users/juliankleutgens/PycharmProjects/task2seq_T5/data_test/or_schema'
  - '/Users/juliankleutgens/PycharmProjects/arc-dsl-main/abstraction-and-reasoning-challenge/training'

load_new_mappings: false
type_of_mapping: 'val2alphabet'

sparse_type: 'repeated2words'

device: 'cpu'
train_on_multiple_gpus: false


output_dir: './outputs/'

extra_token:
  - 'sym_aft_func'
  - 'EoF'

model_params:
  MODEL: "t5-small"
  TRAIN_BATCH_SIZE: 2
  VALID_BATCH_SIZE: 2
  TRAIN_EPOCHS: 2
  VAL_EPOCHS: 2
  LEARNING_RATE: 1.0e-4
  MAX_SOURCE_TEXT_LENGTH: 2048
  MAX_TARGET_TEXT_LENGTH: 512
  SEED: 42

wandb:
  wandb_user: #"your_wandb_user"
  wandb_project: #"your_wandb_project"
  wandb_run_name: #"your_wandb_run_name"  # Optional
  wandb_notes: #"your_wandb_notes"        # Optional