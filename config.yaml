max_samples: 5000
test_samples: 10000

num_of_itr: 5

train_paths:
  - '/home/jkleutgens/training_data'
  - '/home/jkleutgens/reverse_engineering/generated_tasks'

test_mode: false

test_paths:
  - '/home/jkleutgens/data_test/ct_schema'
  - '/home/jkleutgens/data_test/gl_schema'
  - '/home/jkleutgens/data_test/or_schema'
  - '/home/jkleutgens/arc-dsl-main/abstraction-and-reasoning-challenge/training'

load_new_mappings: true
type_of_mapping: 'val2alphabet'

device: 'cuda'
train_on_multiple_gpus: true
n_gpu: 0


sparse_type: 'repeated2words'

output_dir: './outputs/'

extra_token:
  - 'sym_aft_func'
  - 'EoF'
  - 'BoF'

weighted_loss: False
prompting: False

model_params:
  MODEL: "t5-small"
  TRAIN_BATCH_SIZE: 8
  VALID_BATCH_SIZE: 8
  TRAIN_EPOCHS: 2
  VAL_EPOCHS: 1
  LEARNING_RATE: 1.0e-4
  MAX_SOURCE_TEXT_LENGTH: 1024
  MAX_TARGET_TEXT_LENGTH: 1024
  SEED: 42
  NUM_BEAMS: 15
  fined_tuned_dir: '/home/jkleutgens/task2seq_T5/outputs/output_20240618_2121/model_files'



wandb:
  wandb_user: #"your_wandb_user"
  wandb_project: #"your_wandb_project"
  wandb_run_name: #"your_wandb_run_name"  # Optional
  wandb_notes: #"your_wandb_notes"        # Optional