max_samples: 1000
test_samples: 1000

num_of_itr: 15000

train_paths:
  - '/home/jkleutgens/training_data'
  - '/home/jkleutgens/reverse_engineering/generated_tasks'

test_mode: true

test_paths:
  - '/home/jkleutgens/data_test/ct_schema'
  - '/home/jkleutgens/data_test/gl_schema'
  - '/home/jkleutgens/data_test/or_schema'
  - '/home/jkleutgens/arc-dsl-main/abstraction-and-reasoning-challenge/training'

load_new_mappings: true
type_of_mapping: 'val2alphabet'
n_gpu: "0"

device: 'cuda'
train_on_multiple_gpus: true


sparse_type: 'repeated2words'

output_dir: './outputs/'

extra_token:
  - 'sym_aft_func'
  - 'EoF'

model_params:
  MODEL: "t5-small"
  TRAIN_BATCH_SIZE: 8
  VALID_BATCH_SIZE: 8
  TRAIN_EPOCHS: 6
  VAL_EPOCHS: 3
  LEARNING_RATE: 1.0e-4
  MAX_SOURCE_TEXT_LENGTH: 1024
  MAX_TARGET_TEXT_LENGTH: 1024
  SEED: 42

wandb:
  wandb_user: #"your_wandb_user"
  wandb_project: #"your_wandb_project"
  wandb_run_name: #"your_wandb_run_name"  # Optional
  wandb_notes: #"your_wandb_notes"        # Optional